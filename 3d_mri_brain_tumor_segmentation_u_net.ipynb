{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.019525,
          "end_time": "2021-04-28T07:21:37.979493",
          "exception": false,
          "start_time": "2021-04-28T07:21:37.959968",
          "status": "completed"
        },
        "tags": [],
        "id": "c8v0v1eBvasi"
      },
      "source": [
        "# Problem definiton\n",
        "**Segmentation of gliomas in pre-operative MRI scans.**\n",
        "\n",
        "*Each pixel on image must be labeled:*\n",
        "* Pixel is part of a tumor area (1 or 2 or 3) -> can be one of multiple classes / sub-regions\n",
        "* Anything else -> pixel is not on a tumor region (0)\n",
        "\n",
        "The sub-regions of tumor considered for evaluation are: 1) the \"enhancing tumor\" (ET), 2) the \"tumor core\" (TC), and 3) the \"whole tumor\" (WT)\n",
        "The provided segmentation labels have values of 1 for NCR & NET, 2 for ED, 4 for ET, and 0 for everything else.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.018039,
          "end_time": "2021-04-28T07:21:38.015859",
          "exception": false,
          "start_time": "2021-04-28T07:21:37.997820",
          "status": "completed"
        },
        "tags": [],
        "id": "uTqsJpkbvasl"
      },
      "source": [
        "![Brats official annotations](https://www.med.upenn.edu/cbica/assets/user-content/images/BraTS/brats-tumor-subregions.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "gZoAUcXbwF1H",
        "outputId": "ec1defc3-9e3c-4725-fec1-a9eeb43dc956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.9.1-py3-none-any.whl (9.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nilearn) (4.2.6)\n",
            "Collecting scipy>=1.5\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->nilearn) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->nilearn) (3.1.0)\n",
            "Installing collected packages: scipy, nilearn\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed nilearn-0.9.1 scipy-1.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "scipy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.017975,
          "end_time": "2021-04-28T07:21:38.051889",
          "exception": false,
          "start_time": "2021-04-28T07:21:38.033914",
          "status": "completed"
        },
        "tags": [],
        "id": "ZsF-vuy7vasm"
      },
      "source": [
        "# Setup env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-04-28T07:21:38.101295Z",
          "iopub.status.busy": "2021-04-28T07:21:38.100691Z",
          "iopub.status.idle": "2021-04-28T07:22:02.030829Z",
          "shell.execute_reply": "2021-04-28T07:22:02.029653Z"
        },
        "papermill": {
          "duration": 23.960635,
          "end_time": "2021-04-28T07:22:02.031037",
          "exception": false,
          "start_time": "2021-04-28T07:21:38.070402",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-kGbeMFvasm",
        "outputId": "993f41ce-23b6-4509-ba4a-2274e31d66ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/miykael/gif_your_nifti\n",
            "  Cloning https://github.com/miykael/gif_your_nifti to /tmp/pip-req-build-__zrelxd\n",
            "  Running command git clone -q https://github.com/miykael/gif_your_nifti /tmp/pip-req-build-__zrelxd\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gif-your-nifti==0.2.0) (1.21.6)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from gif-your-nifti==0.2.0) (3.0.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from gif-your-nifti==0.2.0) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gif-your-nifti==0.2.0) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio->gif-your-nifti==0.2.0) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gif-your-nifti==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gif-your-nifti==0.2.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gif-your-nifti==0.2.0) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gif-your-nifti==0.2.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->gif-your-nifti==0.2.0) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gif-your-nifti==0.2.0) (1.15.0)\n",
            "Building wheels for collected packages: gif-your-nifti\n",
            "  Building wheel for gif-your-nifti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gif-your-nifti: filename=gif_your_nifti-0.2.0-py3-none-any.whl size=6270 sha256=3ea43528c22d51304db84f1cee909ab7674041c5ffc305e736ecb31c4eb75676\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vb209m5y/wheels/4a/8c/d1/b228c3b67231f7459e8f70d73f4dadaf65cd90692d41f43e88\n",
            "Successfully built gif-your-nifti\n",
            "Installing collected packages: gif-your-nifti\n",
            "Successfully installed gif-your-nifti-0.2.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import PIL\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data\n",
        "from skimage.util import montage \n",
        "import skimage.transform as skTrans\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "from PIL import Image, ImageOps  \n",
        "\n",
        "\n",
        "# neural imaging\n",
        "import nilearn as nl\n",
        "import nibabel as nib\n",
        "import nilearn.plotting as nlplt\n",
        "!pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \n",
        "import gif_your_nifti.core as gif2nif\n",
        "\n",
        "\n",
        "# ml libs\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.callbacks import CSVLogger\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "\n",
        "# Make numpy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:02.082724Z",
          "iopub.status.busy": "2021-04-28T07:22:02.081064Z",
          "iopub.status.idle": "2021-04-28T07:22:02.083317Z",
          "shell.execute_reply": "2021-04-28T07:22:02.083731Z"
        },
        "papermill": {
          "duration": 0.028516,
          "end_time": "2021-04-28T07:22:02.083867",
          "exception": false,
          "start_time": "2021-04-28T07:22:02.055351",
          "status": "completed"
        },
        "tags": [],
        "id": "gp9vE0m_vasp"
      },
      "outputs": [],
      "source": [
        "# DEFINE seg-areas  \n",
        "SEGMENT_CLASSES = {\n",
        "    0 : 'NOT tumor',\n",
        "    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n",
        "    2 : 'EDEMA',\n",
        "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
        "}\n",
        "\n",
        "# there are 155 slices per volume\n",
        "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
        "VOLUME_SLICES = 100 \n",
        "VOLUME_START_AT = 22 # first slice of volume that we will include"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QZUSRUjwxgF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.021069,
          "end_time": "2021-04-28T07:22:02.125899",
          "exception": false,
          "start_time": "2021-04-28T07:22:02.104830",
          "status": "completed"
        },
        "tags": [],
        "id": "y1tY28ALvasp"
      },
      "source": [
        "# Image data descriptions\n",
        "\n",
        "All BraTS multimodal scans are available as  NIfTI files (.nii.gz) -> commonly used medical imaging format to store brain imagin data obtained using MRI and describe different MRI settings \n",
        "1. **T1**: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\n",
        "2. **T1c**: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\n",
        "3. **T2**: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\n",
        "4. **FLAIR**: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\n",
        "\n",
        "Data were acquired with different clinical protocols and various scanners from multiple (n=19) institutions.\n",
        "\n",
        "All the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1), as described both in the BraTS 2012-2013 TMI paper and in the latest BraTS summarizing paper. The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc-1psiN2xda",
        "outputId": "02495c72-2c32-4f58-de9e-b065f84c1b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = 'gdrive/MyDrive/LJMU-Thesis/'"
      ],
      "metadata": {
        "id": "w0fQpXRl236y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "tAVwQAtLyI6q",
        "outputId": "b0e9b2f0-12e5-45ef-80dd-cd37e39f9302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4068aee5-6b11-4828-a535-c796fec27b09\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4068aee5-6b11-4828-a535-c796fec27b09\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 66 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q8ouSjmJeRPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d awsaf49/brats20-dataset-training-validation -p 'gdrive/MyDrive/LJMU-Thesis/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIfT0V4lyQot",
        "outputId": "ee847f20-b8eb-453a-94a0-a3d9d95b7c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brats20-dataset-training-validation.zip to gdrive/MyDrive/LJMU-Thesis\n",
            "100% 4.15G/4.16G [00:32<00:00, 140MB/s]\n",
            "100% 4.16G/4.16G [00:32<00:00, 137MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/brats20-dataset-training-validation.zip -d 'gdrive/MyDrive/LJMU-Thesis/'"
      ],
      "metadata": {
        "id": "B5VYMo9x4xNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:02.176391Z",
          "iopub.status.busy": "2021-04-28T07:22:02.175897Z",
          "iopub.status.idle": "2021-04-28T07:22:03.578230Z",
          "shell.execute_reply": "2021-04-28T07:22:03.578674Z"
        },
        "papermill": {
          "duration": 1.43151,
          "end_time": "2021-04-28T07:22:03.578830",
          "exception": false,
          "start_time": "2021-04-28T07:22:02.147320",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "HnSNoDLsvasq",
        "outputId": "5e7cdf0c-8624-455b-e3b6-6b56a5f8e270"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/LJMU-Thesis/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-00e6c43cd482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mVALIDATION_DATASET_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/MyDrive/LJMU-Thesis/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_image_flair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATASET_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/BraTS20_Training_001/BraTS20_Training_001_flair.nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_image_t1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATASET_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/BraTS20_Training_001/BraTS20_Training_001_t1.nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_image_t1ce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATASET_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/content/gdrive/MyDrive/LJMU-Thesis/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii'"
          ]
        }
      ],
      "source": [
        "TRAIN_DATASET_PATH = '/content/gdrive/MyDrive/LJMU-Thesis/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
        "VALIDATION_DATASET_PATH = '/content/gdrive/MyDrive/LJMU-Thesis/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
        "\n",
        "test_image_flair=nib.load(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\n",
        "test_image_t1=nib.load(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
        "test_image_t1ce=nib.load(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\n",
        "test_image_t2=nib.load(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\n",
        "test_mask=nib.load(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n",
        "\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\n",
        "slice_w = 25\n",
        "ax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\n",
        "ax1.set_title('Image flair')\n",
        "ax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\n",
        "ax2.set_title('Image t1')\n",
        "ax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\n",
        "ax3.set_title('Image t1ce')\n",
        "ax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\n",
        "ax4.set_title('Image t2')\n",
        "ax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\n",
        "ax5.set_title('Mask')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.023238,
          "end_time": "2021-04-28T07:22:03.627120",
          "exception": false,
          "start_time": "2021-04-28T07:22:03.603882",
          "status": "completed"
        },
        "tags": [],
        "id": "V6_0WbDVvasr"
      },
      "source": [
        "**Show whole nifti data -> print each slice from 3d data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:03.692748Z",
          "iopub.status.busy": "2021-04-28T07:22:03.691758Z",
          "iopub.status.idle": "2021-04-28T07:22:04.598863Z",
          "shell.execute_reply": "2021-04-28T07:22:04.599320Z"
        },
        "papermill": {
          "duration": 0.949013,
          "end_time": "2021-04-28T07:22:04.599478",
          "exception": false,
          "start_time": "2021-04-28T07:22:03.650465",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OkO4VBMEvass",
        "outputId": "61d176ad-abe6-45a6-e5df-60b898f2697d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-03f3b078b496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Skip 50:-50 slices since there is not much to see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmontage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_t1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_image_t1' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Skip 50:-50 slices since there is not much to see\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
        "ax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.031221,
          "end_time": "2021-04-28T07:22:04.663212",
          "exception": false,
          "start_time": "2021-04-28T07:22:04.631991",
          "status": "completed"
        },
        "tags": [],
        "id": "_7Llw-q3vast"
      },
      "source": [
        "**Show segment of tumor for each above slice**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:04.746851Z",
          "iopub.status.busy": "2021-04-28T07:22:04.746016Z",
          "iopub.status.idle": "2021-04-28T07:22:05.446688Z",
          "shell.execute_reply": "2021-04-28T07:22:05.446216Z"
        },
        "papermill": {
          "duration": 0.752028,
          "end_time": "2021-04-28T07:22:05.446835",
          "exception": false,
          "start_time": "2021-04-28T07:22:04.694807",
          "status": "completed"
        },
        "tags": [],
        "id": "GLJytsAMvast"
      },
      "outputs": [],
      "source": [
        "# Skip 50:-50 slices since there is not much to see\n",
        "fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\n",
        "ax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:05.520180Z",
          "iopub.status.busy": "2021-04-28T07:22:05.519352Z",
          "iopub.status.idle": "2021-04-28T07:22:09.486525Z",
          "shell.execute_reply": "2021-04-28T07:22:09.486020Z"
        },
        "papermill": {
          "duration": 4.004929,
          "end_time": "2021-04-28T07:22:09.486712",
          "exception": false,
          "start_time": "2021-04-28T07:22:05.481783",
          "status": "completed"
        },
        "tags": [],
        "id": "HJWI3Z52vasu"
      },
      "outputs": [],
      "source": [
        "shutil.copy2(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_flair.nii', './test_gif_BraTS20_Training_001_flair.nii')\n",
        "gif2nif.write_gif_normal('./test_gif_BraTS20_Training_001_flair.nii')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.03453,
          "end_time": "2021-04-28T07:22:09.555918",
          "exception": false,
          "start_time": "2021-04-28T07:22:09.521388",
          "status": "completed"
        },
        "tags": [],
        "id": "8vxkH2EUvasu"
      },
      "source": [
        "**Gif representation of slices in 3D volume**\n",
        "<img src=\"https://media1.tenor.com/images/15427ffc1399afc3334f12fd27549a95/tenor.gif?itemid=20554734\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.033849,
          "end_time": "2021-04-28T07:22:09.623960",
          "exception": false,
          "start_time": "2021-04-28T07:22:09.590111",
          "status": "completed"
        },
        "tags": [],
        "id": "BrzBEnSHvasv"
      },
      "source": [
        "**Show segments of tumor using different effects**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:09.698998Z",
          "iopub.status.busy": "2021-04-28T07:22:09.698151Z",
          "iopub.status.idle": "2021-04-28T07:22:16.213047Z",
          "shell.execute_reply": "2021-04-28T07:22:16.213455Z"
        },
        "papermill": {
          "duration": 6.555709,
          "end_time": "2021-04-28T07:22:16.213614",
          "exception": false,
          "start_time": "2021-04-28T07:22:09.657905",
          "status": "completed"
        },
        "tags": [],
        "id": "u6VchGZOvasv"
      },
      "outputs": [],
      "source": [
        "niimg = nl.image.load_img(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_flair.nii')\n",
        "nimask = nl.image.load_img(TRAIN_DATASET_PATH + '/BraTS20_Training_001/BraTS20_Training_001_seg.nii')\n",
        "\n",
        "fig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n",
        "\n",
        "\n",
        "nlplt.plot_anat(niimg,\n",
        "                title='BraTS20_Training_001_flair.nii plot_anat',\n",
        "                axes=axes[0])\n",
        "\n",
        "nlplt.plot_epi(niimg,\n",
        "               title='BraTS20_Training_001_flair.nii plot_epi',\n",
        "               axes=axes[1])\n",
        "\n",
        "nlplt.plot_img(niimg,\n",
        "               title='BraTS20_Training_001_flair.nii plot_img',\n",
        "               axes=axes[2])\n",
        "\n",
        "nlplt.plot_roi(nimask, \n",
        "               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n",
        "               bg_img=niimg, \n",
        "               axes=axes[3], cmap='Paired')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.045999,
          "end_time": "2021-04-28T07:22:16.306607",
          "exception": false,
          "start_time": "2021-04-28T07:22:16.260608",
          "status": "completed"
        },
        "tags": [],
        "id": "RiGOS3z7vasv"
      },
      "source": [
        "# Create model || U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
        "he u-net is convolutional network architecture for fast and precise segmentation of images. Up to now it has outperformed the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. It has won the Grand Challenge for Computer-Automated Detection of Caries in Bitewing Radiography at ISBI 2015, and it has won the Cell Tracking Challenge at ISBI 2015 on the two most challenging transmitted light microscopy categories (Phase contrast and DIC microscopy) by a large margin\n",
        "[more on](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
        "![official definiton](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.04532,
          "end_time": "2021-04-28T07:22:16.397241",
          "exception": false,
          "start_time": "2021-04-28T07:22:16.351921",
          "status": "completed"
        },
        "tags": [],
        "id": "PVZ_LgPOvasw"
      },
      "source": [
        "# Loss function\n",
        "**Dice coefficient**\n",
        ", which is essentially a measure of overlap between two samples. This measure ranges from 0 to 1 where a Dice coefficient of 1 denotes perfect and complete overlap. The Dice coefficient was originally developed for binary data, and can be calculated as:\n",
        "\n",
        "![dice loss](https://wikimedia.org/api/rest_v1/media/math/render/svg/a80a97215e1afc0b222e604af1b2099dc9363d3b)\n",
        "\n",
        "**As matrices**\n",
        "![dice loss](https://www.jeremyjordan.me/content/images/2018/05/intersection-1.png)\n",
        "\n",
        "[Implementation, (images above) and explanation can be found here](https://www.jeremyjordan.me/semantic-segmentation/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:16.504184Z",
          "iopub.status.busy": "2021-04-28T07:22:16.503407Z",
          "iopub.status.idle": "2021-04-28T07:22:16.505827Z",
          "shell.execute_reply": "2021-04-28T07:22:16.506311Z"
        },
        "papermill": {
          "duration": 0.063838,
          "end_time": "2021-04-28T07:22:16.506440",
          "exception": false,
          "start_time": "2021-04-28T07:22:16.442602",
          "status": "completed"
        },
        "tags": [],
        "id": "jbIxLP2mvasw"
      },
      "outputs": [],
      "source": [
        "# dice loss as defined above for 4 classes\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    class_num = 4\n",
        "    for i in range(class_num):\n",
        "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
        "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
        "   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n",
        "        if i == 0:\n",
        "            total_loss = loss\n",
        "        else:\n",
        "            total_loss = total_loss + loss\n",
        "    total_loss = total_loss / class_num\n",
        "#    K.print_tensor(total_loss, message=' total dice coef: ')\n",
        "    return total_loss\n",
        "\n",
        "\n",
        " \n",
        "# define per class evaluation of dice coef\n",
        "# inspired by https://github.com/keras-team/keras/issues/9395\n",
        "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
        "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
        "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
        "\n",
        "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
        "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
        "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
        "\n",
        "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
        "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
        "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
        "\n",
        "\n",
        "\n",
        "# Computing Precision \n",
        "def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    \n",
        "# Computing Sensitivity      \n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "\n",
        "# Computing Specificity\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:16.602017Z",
          "iopub.status.busy": "2021-04-28T07:22:16.601348Z",
          "iopub.status.idle": "2021-04-28T07:22:16.604301Z",
          "shell.execute_reply": "2021-04-28T07:22:16.603904Z"
        },
        "papermill": {
          "duration": 0.052245,
          "end_time": "2021-04-28T07:22:16.604408",
          "exception": false,
          "start_time": "2021-04-28T07:22:16.552163",
          "status": "completed"
        },
        "tags": [],
        "id": "R7wPk8Ckvasx"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "0Kj89iZs_fZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:16.717492Z",
          "iopub.status.busy": "2021-04-28T07:22:16.711797Z",
          "iopub.status.idle": "2021-04-28T07:22:19.920172Z",
          "shell.execute_reply": "2021-04-28T07:22:19.920568Z"
        },
        "papermill": {
          "duration": 3.268565,
          "end_time": "2021-04-28T07:22:19.920775",
          "exception": false,
          "start_time": "2021-04-28T07:22:16.652210",
          "status": "completed"
        },
        "tags": [],
        "id": "ST0Miu-Lvasx"
      },
      "outputs": [],
      "source": [
        "# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
        "\n",
        "def build_unet(inputs, ker_init, dropout):\n",
        "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
        "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
        "    \n",
        "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
        "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
        "    \n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
        "    \n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
        "    \n",
        "    \n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
        "    drop5 = Dropout(dropout)(conv5)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
        "    \n",
        "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
        "    merge = concatenate([conv1,up], axis = 3)\n",
        "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
        "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
        "    \n",
        "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
        "\n",
        "model = build_unet(input_layer, 'he_normal', 0.2)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.046261,
          "end_time": "2021-04-28T07:22:20.013538",
          "exception": false,
          "start_time": "2021-04-28T07:22:19.967277",
          "status": "completed"
        },
        "tags": [],
        "id": "-3KdxQpEvasx"
      },
      "source": [
        "**model architecture** <br>\n",
        "If you are about to use U-NET, I suggest to check out this awesome library that I found later, after manual implementation of U-NET [keras-unet-collection](https://pypi.org/project/keras-unet-collection/), which also contains implementation of dice loss, tversky loss and many more!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:20.111056Z",
          "iopub.status.busy": "2021-04-28T07:22:20.110468Z",
          "iopub.status.idle": "2021-04-28T07:22:20.998901Z",
          "shell.execute_reply": "2021-04-28T07:22:20.999319Z"
        },
        "papermill": {
          "duration": 0.939448,
          "end_time": "2021-04-28T07:22:20.999468",
          "exception": false,
          "start_time": "2021-04-28T07:22:20.060020",
          "status": "completed"
        },
        "tags": [],
        "id": "4s0Ca5xivasy"
      },
      "outputs": [],
      "source": [
        "plot_model(model, \n",
        "           show_shapes = True,\n",
        "           show_dtype=False,\n",
        "           show_layer_names = True, \n",
        "           rankdir = 'TB', \n",
        "           expand_nested = False, \n",
        "           dpi = 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.052155,
          "end_time": "2021-04-28T07:22:21.106528",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.054373",
          "status": "completed"
        },
        "tags": [],
        "id": "1pJE1WrIvasy"
      },
      "source": [
        "# Load data\n",
        "Loading all data into memory is not a good idea since the data are too big to fit in.\n",
        "So we will create dataGenerators - load data on the fly as explained [here](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:21.218397Z",
          "iopub.status.busy": "2021-04-28T07:22:21.217787Z",
          "iopub.status.idle": "2021-04-28T07:22:21.268847Z",
          "shell.execute_reply": "2021-04-28T07:22:21.268268Z"
        },
        "papermill": {
          "duration": 0.1102,
          "end_time": "2021-04-28T07:22:21.268971",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.158771",
          "status": "completed"
        },
        "tags": [],
        "id": "epGgAaHTvasy"
      },
      "outputs": [],
      "source": [
        "# lists of directories with studies\n",
        "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
        "\n",
        "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
        "train_and_val_directories.remove(TRAIN_DATASET_PATH+'/BraTS20_Training_355')\n",
        "\n",
        "\n",
        "def pathListIntoIds(dirList):\n",
        "    x = []\n",
        "    for i in range(0,len(dirList)):\n",
        "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
        "    return x\n",
        "\n",
        "train_and_test_ids = pathListIntoIds(train_and_val_directories); \n",
        "\n",
        "    \n",
        "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \n",
        "train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.117125,
          "end_time": "2021-04-28T07:22:21.440676",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.323551",
          "status": "completed"
        },
        "tags": [],
        "id": "v0S2v8Fbvasz"
      },
      "source": [
        "**Override Keras sequence DataGenerator class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:21.563883Z",
          "iopub.status.busy": "2021-04-28T07:22:21.563132Z",
          "iopub.status.idle": "2021-04-28T07:22:21.565782Z",
          "shell.execute_reply": "2021-04-28T07:22:21.566155Z"
        },
        "papermill": {
          "duration": 0.072355,
          "end_time": "2021-04-28T07:22:21.566290",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.493935",
          "status": "completed"
        },
        "tags": [],
        "id": "m_DSQ2opvasz"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(Batch_ids)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, Batch_ids):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
        "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
        "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
        "\n",
        "        \n",
        "        # Generate data\n",
        "        for c, i in enumerate(Batch_ids):\n",
        "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
        "\n",
        "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
        "            flair = nib.load(data_path).get_fdata()    \n",
        "\n",
        "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
        "            ce = nib.load(data_path).get_fdata()\n",
        "            \n",
        "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
        "            seg = nib.load(data_path).get_fdata()\n",
        "        \n",
        "            for j in range(VOLUME_SLICES):\n",
        "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "\n",
        "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
        "                    \n",
        "        # Generate masks\n",
        "        y[y==4] = 3;\n",
        "        mask = tf.one_hot(y, 4);\n",
        "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
        "        return X/np.max(X), Y\n",
        "        \n",
        "training_generator = DataGenerator(train_ids)\n",
        "valid_generator = DataGenerator(val_ids)\n",
        "test_generator = DataGenerator(test_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.052579,
          "end_time": "2021-04-28T07:22:21.671267",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.618688",
          "status": "completed"
        },
        "tags": [],
        "id": "ANgHE_XZvasz"
      },
      "source": [
        "**Number of data used**\n",
        "for training / testing / validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:21.791262Z",
          "iopub.status.busy": "2021-04-28T07:22:21.790429Z",
          "iopub.status.idle": "2021-04-28T07:22:21.901894Z",
          "shell.execute_reply": "2021-04-28T07:22:21.902312Z"
        },
        "papermill": {
          "duration": 0.171418,
          "end_time": "2021-04-28T07:22:21.902456",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.731038",
          "status": "completed"
        },
        "tags": [],
        "id": "M8Ay0s_Cvas0"
      },
      "outputs": [],
      "source": [
        "# show number of data for each dir \n",
        "def showDataLayout():\n",
        "    plt.bar([\"Train\",\"Valid\",\"Test\"],\n",
        "    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.ylabel('Number of images')\n",
        "    plt.title('Data distribution')\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "showDataLayout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.053389,
          "end_time": "2021-04-28T07:22:22.009932",
          "exception": false,
          "start_time": "2021-04-28T07:22:21.956543",
          "status": "completed"
        },
        "tags": [],
        "id": "MAbD9kBJvas0"
      },
      "source": [
        "**Add callback for training process**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:22.123044Z",
          "iopub.status.busy": "2021-04-28T07:22:22.122237Z",
          "iopub.status.idle": "2021-04-28T07:22:22.124817Z",
          "shell.execute_reply": "2021-04-28T07:22:22.124401Z"
        },
        "papermill": {
          "duration": 0.060964,
          "end_time": "2021-04-28T07:22:22.124929",
          "exception": false,
          "start_time": "2021-04-28T07:22:22.063965",
          "status": "completed"
        },
        "tags": [],
        "id": "3shhLzDxvas1"
      },
      "outputs": [],
      "source": [
        "csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
        "#                               patience=2, verbose=1, mode='auto'),\n",
        "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1),\n",
        "#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
        "#                             verbose=1, save_best_only=True, save_weights_only = True)\n",
        "        csv_logger\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.052746,
          "end_time": "2021-04-28T07:22:22.230223",
          "exception": false,
          "start_time": "2021-04-28T07:22:22.177477",
          "status": "completed"
        },
        "tags": [],
        "id": "M-13EFhwvas1"
      },
      "source": [
        "# Train model\n",
        "My best model was trained with 81% accuracy on mean IOU and 65.5% on Dice loss <br>\n",
        "I will load this pretrained model instead of training again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:22.341490Z",
          "iopub.status.busy": "2021-04-28T07:22:22.340683Z",
          "iopub.status.idle": "2021-04-28T07:22:22.345753Z",
          "shell.execute_reply": "2021-04-28T07:22:22.345329Z"
        },
        "papermill": {
          "duration": 0.062646,
          "end_time": "2021-04-28T07:22:22.345864",
          "exception": false,
          "start_time": "2021-04-28T07:22:22.283218",
          "status": "completed"
        },
        "tags": [],
        "id": "rffwhXduvas1"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "# history =  model.fit(training_generator,\n",
        "#                     epochs=35,\n",
        "#                     steps_per_epoch=len(train_ids),\n",
        "#                     callbacks= callbacks,\n",
        "#                     validation_data = valid_generator\n",
        "#                     )  \n",
        "# model.save(\"model_x1_1.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.052846,
          "end_time": "2021-04-28T07:22:22.456338",
          "exception": false,
          "start_time": "2021-04-28T07:22:22.403492",
          "status": "completed"
        },
        "tags": [],
        "id": "IYkuwLhlvas1"
      },
      "source": [
        "**Visualize the training process**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OdHXH8OcehgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MbOI3SV7eh7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "isLiWZRofE5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rastislav/modelperclasseval"
      ],
      "metadata": {
        "id": "EhtMUM7seZby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "zTxjbaqnfPjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q modelperclasseval.zip -d '/content/drive/MyDrive/LJMU-Thesis/modelperclasseval/'"
      ],
      "metadata": {
        "id": "GYzQcgk_fU7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:22.576068Z",
          "iopub.status.busy": "2021-04-28T07:22:22.575451Z",
          "iopub.status.idle": "2021-04-28T07:22:24.687167Z",
          "shell.execute_reply": "2021-04-28T07:22:24.687546Z"
        },
        "papermill": {
          "duration": 2.178458,
          "end_time": "2021-04-28T07:22:24.687715",
          "exception": false,
          "start_time": "2021-04-28T07:22:22.509257",
          "status": "completed"
        },
        "tags": [],
        "id": "vRtUSr6dvas2"
      },
      "outputs": [],
      "source": [
        "############ load trained model ################\n",
        "model = keras.models.load_model('/content/drive/MyDrive/LJMU-Thesis/modelperclasseval/model_per_class.h5', \n",
        "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
        "                                                   \"dice_coef\": dice_coef,\n",
        "                                                   \"precision\": precision,\n",
        "                                                   \"sensitivity\":sensitivity,\n",
        "                                                   \"specificity\":specificity,\n",
        "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
        "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
        "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
        "                                                  }, compile=False)\n",
        "\n",
        "history = pd.read_csv('/content/drive/MyDrive/LJMU-Thesis/modelperclasseval/training_per_class.log', sep=',', engine='python')\n",
        "\n",
        "hist=history\n",
        "\n",
        "############### ########## ####### #######\n",
        "\n",
        "# hist=history.history\n",
        "\n",
        "acc=hist['accuracy']\n",
        "val_acc=hist['val_accuracy']\n",
        "\n",
        "epoch=range(len(acc))\n",
        "\n",
        "loss=hist['loss']\n",
        "val_loss=hist['val_loss']\n",
        "\n",
        "train_dice=hist['dice_coef']\n",
        "val_dice=hist['val_dice_coef']\n",
        "\n",
        "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
        "\n",
        "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
        "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
        "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
        "ax[1].legend()\n",
        "\n",
        "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
        "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
        "ax[2].legend()\n",
        "\n",
        "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
        "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
        "ax[3].legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.056144,
          "end_time": "2021-04-28T07:22:24.802431",
          "exception": false,
          "start_time": "2021-04-28T07:22:24.746287",
          "status": "completed"
        },
        "tags": [],
        "id": "1rd0B03kvas2"
      },
      "source": [
        "# Prediction examples "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kheq4M06eXRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dal8nvpkeWSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:24.929598Z",
          "iopub.status.busy": "2021-04-28T07:22:24.922182Z",
          "iopub.status.idle": "2021-04-28T07:22:24.931538Z",
          "shell.execute_reply": "2021-04-28T07:22:24.931932Z"
        },
        "papermill": {
          "duration": 0.074134,
          "end_time": "2021-04-28T07:22:24.932068",
          "exception": false,
          "start_time": "2021-04-28T07:22:24.857934",
          "status": "completed"
        },
        "tags": [],
        "id": "rulilj1yvas2"
      },
      "outputs": [],
      "source": [
        "# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n",
        "# returns volume of specified study at `path`\n",
        "def imageLoader(path):\n",
        "    image = nib.load(path).get_fdata()\n",
        "    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
        "    for j in range(VOLUME_SLICES):\n",
        "        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
        "\n",
        "        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
        "    return np.array(image)\n",
        "\n",
        "\n",
        "# load nifti file at `path`\n",
        "# and load each slice with mask from volume\n",
        "# choose the mri type & resize to `IMG_SIZE`\n",
        "def loadDataFromDir(path, list_of_files, mriType, n_images):\n",
        "    scans = []\n",
        "    masks = []\n",
        "    for i in list_of_files[:n_images]:\n",
        "        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n",
        "        currentScanVolume = imageLoader(fullPath)\n",
        "        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n",
        "        # for each slice in 3D volume, find also it's mask\n",
        "        for j in range(0, currentScanVolume.shape[2]):\n",
        "            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
        "            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
        "            scans.append(scan_img[..., np.newaxis])\n",
        "            masks.append(mask_img[..., np.newaxis])\n",
        "    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n",
        "        \n",
        "#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:25.063463Z",
          "iopub.status.busy": "2021-04-28T07:22:25.062905Z",
          "iopub.status.idle": "2021-04-28T07:22:38.006435Z",
          "shell.execute_reply": "2021-04-28T07:22:38.005935Z"
        },
        "papermill": {
          "duration": 13.019132,
          "end_time": "2021-04-28T07:22:38.006565",
          "exception": false,
          "start_time": "2021-04-28T07:22:24.987433",
          "status": "completed"
        },
        "tags": [],
        "id": "X1AjT2r0vas2"
      },
      "outputs": [],
      "source": [
        "def predictByPath(case_path,case):\n",
        "    files = next(os.walk(case_path))[2]\n",
        "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
        "  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n",
        "    \n",
        "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n",
        "    flair=nib.load(vol_path).get_fdata()\n",
        "    \n",
        "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n",
        "    ce=nib.load(vol_path).get_fdata() \n",
        "    \n",
        " #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n",
        " #   seg=nib.load(vol_path).get_fdata()  \n",
        "\n",
        "    \n",
        "    for j in range(VOLUME_SLICES):\n",
        "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
        "        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
        " #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n",
        "    return model.predict(X/np.max(X), verbose=1)\n",
        "\n",
        "\n",
        "def showPredictsById(case, start_slice = 60):\n",
        "    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
        "    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
        "    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
        "    p = predictByPath(path,case)\n",
        "\n",
        "    core = p[:,:,:,1]\n",
        "    edema= p[:,:,:,2]\n",
        "    enhancing = p[:,:,:,3]\n",
        "\n",
        "    plt.figure(figsize=(18, 50))\n",
        "    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n",
        "\n",
        "    for i in range(6): # for each image, add brain background\n",
        "        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
        "    \n",
        "    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
        "    axarr[0].title.set_text('Original image flair')\n",
        "    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
        "    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
        "    axarr[1].title.set_text('Ground truth')\n",
        "    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
        "    axarr[2].title.set_text('all classes')\n",
        "    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
        "    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
        "    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
        "    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
        "    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
        "    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "showPredictsById(case=test_ids[0][-3:])\n",
        "showPredictsById(case=test_ids[1][-3:])\n",
        "showPredictsById(case=test_ids[2][-3:])\n",
        "showPredictsById(case=test_ids[3][-3:])\n",
        "showPredictsById(case=test_ids[4][-3:])\n",
        "showPredictsById(case=test_ids[5][-3:])\n",
        "showPredictsById(case=test_ids[6][-3:])\n",
        "\n",
        "\n",
        "# mask = np.zeros((10,10))\n",
        "# mask[3:-3, 3:-3] = 1 # white square in black background\n",
        "# im = mask + np.random.randn(10,10) * 0.01 # random image\n",
        "# masked = np.ma.masked_where(mask == 0, mask)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.imshow(im, 'gray', interpolation='none')\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.imshow(im, 'gray', interpolation='none')\n",
        "# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.078003,
          "end_time": "2021-04-28T07:22:38.166441",
          "exception": false,
          "start_time": "2021-04-28T07:22:38.088438",
          "status": "completed"
        },
        "tags": [],
        "id": "_E-5VFTjvas4"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": false,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:38.332157Z",
          "iopub.status.busy": "2021-04-28T07:22:38.331314Z",
          "iopub.status.idle": "2021-04-28T07:22:38.986983Z",
          "shell.execute_reply": "2021-04-28T07:22:38.987408Z"
        },
        "papermill": {
          "duration": 0.742079,
          "end_time": "2021-04-28T07:22:38.987557",
          "exception": false,
          "start_time": "2021-04-28T07:22:38.245478",
          "status": "completed"
        },
        "tags": [],
        "id": "3qaJOzBevas5"
      },
      "outputs": [],
      "source": [
        "case = case=test_ids[3][-3:]\n",
        "path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
        "gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
        "p = predictByPath(path,case)\n",
        "\n",
        "\n",
        "core = p[:,:,:,1]\n",
        "edema= p[:,:,:,2]\n",
        "enhancing = p[:,:,:,3]\n",
        "\n",
        "\n",
        "i=40 # slice at\n",
        "eval_class = 2 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n",
        "\n",
        "\n",
        "\n",
        "gt[gt != eval_class] = 1 # use only one class for per class evaluation \n",
        "\n",
        "resized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "plt.figure()\n",
        "f, axarr = plt.subplots(1,2) \n",
        "axarr[0].imshow(resized_gt, cmap=\"gray\")\n",
        "axarr[0].title.set_text('ground truth')\n",
        "axarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\n",
        "axarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-28T07:22:39.271660Z",
          "iopub.status.busy": "2021-04-28T07:22:39.269938Z",
          "iopub.status.idle": "2021-04-28T07:23:07.684105Z",
          "shell.execute_reply": "2021-04-28T07:23:07.683185Z"
        },
        "papermill": {
          "duration": 28.564268,
          "end_time": "2021-04-28T07:23:07.684272",
          "exception": false,
          "start_time": "2021-04-28T07:22:39.120004",
          "status": "completed"
        },
        "tags": [],
        "id": "PVH9rM0Kvas5"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.091362,
          "end_time": "2021-04-28T07:23:07.869284",
          "exception": false,
          "start_time": "2021-04-28T07:23:07.777922",
          "status": "completed"
        },
        "tags": [],
        "id": "1QDFSzgmvas5"
      },
      "source": [
        "# Survival prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.096189,
          "end_time": "2021-04-28T07:23:08.059307",
          "exception": false,
          "start_time": "2021-04-28T07:23:07.963118",
          "status": "completed"
        },
        "tags": [],
        "id": "S2dnL_avvas5"
      },
      "source": [
        "Full implementation can be found in my another notebook: https://www.kaggle.com/rastislav/mri-brain-tumor-survival-prediction"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 97.878413,
      "end_time": "2021-04-28T07:23:11.079191",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-04-28T07:21:33.200778",
      "version": "2.2.2"
    },
    "colab": {
      "name": "3d-mri-brain-tumor-segmentation-u-net.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}